{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of text documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "# %pylab inline\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import OAG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15034\n"
     ]
    }
   ],
   "source": [
    "# load OAG online data\n",
    "oag_data = pd.read_csv(\"../data/OAG Complaints-Online_Final.csv\")\n",
    "oag_doc = list(oag_data['COMPLAINT_DESCRIPTION'])\n",
    "print len(oag_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'Note User indicated supporting documents will be mailed within - days They rent cars for Uber to TLC drivers in NYC  There cars are problematic and inoperableYou can see the google reviews or BBB complaints against themThey have our ---- usd deposit and one week of rent --- plus loss of wages for two drivers ie ---- usd']\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate\n",
    "oag_doc = list(set(oag_doc))\n",
    "print oag_doc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11635\n"
     ]
    }
   ],
   "source": [
    "# remove nan\n",
    "oag_doc = oag_doc[1:]\n",
    "\n",
    "print len(oag_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7401520\n"
     ]
    }
   ],
   "source": [
    "# load tweets\n",
    "twitterdata = pd.read_csv(\"../data/fraud_list_svarmit_location_v1.csv\", header=None)\n",
    "tweet_doc = list(twitterdata.iloc[:,0])\n",
    "print len(twitterdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20076\n"
     ]
    }
   ],
   "source": [
    "# random select 30000 tweets\n",
    "selected_tweet_index = list(randint(0, len(tweet_doc),100000))\n",
    "\n",
    "# filter meaningless tweets\n",
    "selected_tweet = [tweet_doc[i] for i in selected_tweet_index if type(tweet_doc[i]) == str and len(tweet_doc[i].split()) > 20]\n",
    "\n",
    "print len(selected_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19818\n"
     ]
    }
   ],
   "source": [
    "# Get random 1000000 unselected tweet\n",
    "unselected_tweet_index =[]\n",
    "count = 0\n",
    "for i in randint(0, len(tweet_doc), 3000000):\n",
    "    if i not in selected_tweet_index:\n",
    "        unselected_tweet_index.append(i)\n",
    "        count += 1\n",
    "        if count == 100000:\n",
    "            break\n",
    "            \n",
    "unselected_tweet = [tweet_doc[i] for i in unselected_tweet_index if type(tweet_doc[i]) == str and len(tweet_doc[i].split()) > 20]\n",
    "\n",
    "print len(unselected_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn text feature extraction -- TfidfVectorizer\n",
    "class sklearn.feature_extraction.text.TfidfVectorizer(input='content', encoding='utf-8', decode_error='strict', strip_accents=None, lowercase=True, preprocessor=None, tokenizer=None, analyzer='word', stop_words=None, token_pattern='(?u)\\b\\w\\w+\\b', ngram_range=(1, 1), max_df=1.0, min_df=1, max_features=None, vocabulary=None, binary=False, dtype=<class 'numpy.int64'>, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)[source]Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of OAG data (fraud relevent): 11635\n",
      "The length of general tweets (nonfraud relevent): 20076\n",
      "The length of whole dataset: 31711\n"
     ]
    }
   ],
   "source": [
    "# combine corpus\n",
    "raw_whole_corpus = oag_doc + selected_tweet\n",
    "print \"The length of OAG data (fraud relevent):\", len(oag_doc)\n",
    "print \"The length of general tweets (nonfraud relevent):\", len(selected_tweet)\n",
    "print \"The length of whole dataset:\", len(raw_whole_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "31711\n"
     ]
    }
   ],
   "source": [
    "# Creat target\n",
    "target = [1]*len(oag_doc)+[0]*len(selected_tweet)\n",
    "print target[:10]\n",
    "print target[-10:]\n",
    "print len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note User indicated supporting documents will be mailed within - days They rent cars for Uber to TLC drivers in NYC  There cars are problematic and inoperableYou can see the google reviews or BBB complaints against themThey have our ---- usd deposit and one week of rent --- plus loss of wages for two drivers ie ---- usd'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_whole_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31711x7644 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 693412 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn text feature extraction -- TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10, stop_words='english')\n",
    "X = vectorizer.fit_transform(raw_whole_corpus)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classification model with Naive Bayes, SVM linear, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, target_train, target_test = train_test_split(X.toarray(), target, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by Naive Bayes =', 0.9612150515030481)\n",
      "Training it took 0.2 mins\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classification\n",
    "start_time = time.time()\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, target_train)\n",
    "pred = gnb.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by Naive Bayes =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by SVM with linear =', 0.9910657977717049)\n",
      "Training it took 11.9 mins\n"
     ]
    }
   ],
   "source": [
    "# SVM linear\n",
    "start_time = time.time()\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, target_train)\n",
    "pred = svc.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by SVM with linear =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by Random Forest =', 0.9850746268656716)\n",
      "Training it took 7.5 mins\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n",
    "clf = clf.fit(X_train, target_train)\n",
    "pred = clf.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by Random Forest =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on unselected Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19818\n"
     ]
    }
   ],
   "source": [
    "print len(unselected_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19818x7644 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 200690 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting features from the test data using the same vectorizer\n",
    "X_unselected_tweet = vectorizer.transform(unselected_tweet)\n",
    "X_unselected_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Apply SVM model on unselected Tweets\n",
    "svc_pred = svc.predict(X_unselected_tweet.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_fraud_tweet_index = [i for i,j in enumerate(svc_pred) if j ==1]\n",
    "len(pred_fraud_tweet_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before draining their bank accounts dry. Or worse commit crimes and pin it on the victim. I keep getting phone calls from one scammer 2/\n",
      "----------------------\n",
      "@mb @ElaineChase did you not see the two Idyllic Tutors on the book? Also its a very artifact-or-enchantment looking book, not spell-looking\n",
      "----------------------\n",
      "I would probably have at the very least another extra  $1000 in my bank account if I stopped taking cabs everywhere\n",
      "----------------------\n",
      "@Pat_The_Phantom I work Operating Room specifically pre op and recovery so it happens a lot. Children especially. I sing with them most days\n",
      "----------------------\n",
      "Consumer: Media tells me you're good. Here's money.\n",
      "\n",
      "Obviously [insert artist] is the greatest of all time. Look at the sales.\n",
      "----------------------\n",
      "in honor of being called Fara at our track meet at DR I will be going by Fara for the rest of the school year.\n",
      "----------------------\n",
      "After throwing my outdoor plants behind a shed, my landlord moved the plants INSIDE my house to the shade. She's botanical serial killer.\n",
      "----------------------\n",
      "@NewDay @ChrisCuomo ?FBI called her. She says no but FBI calls her attorney Did u ask Haiti 19b where is money/Tyson Chicken  how much bribe\n",
      "----------------------\n",
      "Lord he was so fine my GOD. I was driving and he kept following me and then he got out of the car to close his gas tank at a red light\n",
      "----------------------\n",
      "INBOX: NYS AG Schneiderman sues Dominos Pizza, Inc. \"alleging that they underpaid workers at least $565,000 at ten stores in New York.\"\n",
      "----------------------\n",
      "@VivziePop you can probably contact customer support and/or your bank and get your money back since it was a shady operation\n",
      "----------------------\n",
      "@CoryBooker @POTUS So srsly bots buying up tickets so resellers can inflate prices so experiences are for the top 1% should be illegal.\n",
      "----------------------\n",
      "Manu Lall, from Columbia University: Two-thirds of my water bill in NYC is from treating the water after we use it.\n",
      "#knowwater\n",
      "----------------------\n",
      "You know you work too much when customers ask you if you ever go home because you're here all the time\n",
      "----------------------\n",
      "So there is some optimal level where asset owners will delegate active management or could implement it on their own using factor investing\n",
      "----------------------\n",
      "@Zimtsternlein @Katha_Pe It's the World Financial Center in downtown Manhattan. I sit in a public space and use their WiFi. #startuplife\n",
      "----------------------\n",
      "Honestly sick of moving home to Plattsburgh back home to the zap house to Albany back home to syracuse back to Albany then platts back home\n",
      "----------------------\n",
      "A4.  Illegal dumping happens when companies do not want to pay the fees at landfills/ in authorized areas. Report them. #wastestopswithme\n",
      "----------------------\n",
      "@SavageNation THE BOOK WAS SOLD FOR .50 FIFTY CENTS IN THE REJECTED BOXES OF K MART ,NO BODY BOUGHT THAT SHITTY BOOK\n",
      "----------------------\n",
      " so if you are interested in launching a music service without building the whole damn thing 7digital is the only game in town now?\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in pred_fraud_tweet_index[:20]:\n",
    "    print unselected_tweet[i]\n",
    "    print '----------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "# Apply random forest model on unselected Tweets\n",
    "clf_pred = clf.predict(X_unselected_tweet.toarray())\n",
    "\n",
    "clf_pred_fraud_tweet_index = [i for i,j in enumerate(clf_pred) if j ==1]\n",
    "print len(clf_pred_fraud_tweet_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He's not striking out much. Getting on base. Making contact. Running bases well and even the oldest and lamest fan can't knock his hustle.\n",
      "----------------------\n",
      "Never met @DaveNavarro but I was once behind Perry Farrell at an Am/Pm near Sunset Strip at 3am. That was interesting.\n",
      "----------------------\n",
      "Before draining their bank accounts dry. Or worse commit crimes and pin it on the victim. I keep getting phone calls from one scammer 2/\n",
      "----------------------\n",
      "@CopsInTraining Do Notts response PC 's keep the crimes they report? Or  are they handed over for secondary investigation? Good luck in PPD!\n",
      "----------------------\n",
      "When a hot foreign exchange student asks Jordan on a coffee date and I can't even get my fuckin dog to hug me for .02 seconds\n",
      "----------------------\n",
      "I tweet about junk food so much that all of the promoted tweets on my feed are for cookies, candy or crackers, and nothing else \n",
      "----------------------\n",
      "you're investigating suspicious activity from \"Emergency\" In other folks who submitted it up by golly, I was stolen wallet returned via\n",
      "----------------------\n",
      "@rosevalenta You really think any company would run the risk of lawsuit by lying about POTUS candidate? If false Cruz should sued but DIDNT.\n",
      "----------------------\n",
      "It only matters because the modern reading of the show casts Eliza as a progressive female hero, who drags herself up by her own bootstraps.\n",
      "----------------------\n",
      "I would probably have at the very least another extra  $1000 in my bank account if I stopped taking cabs everywhere\n",
      "----------------------\n",
      "@KZapponeTD @nycinews @DCYAPress typical unfair and limited scheme from a Civil Service out of touch. Pity Minister does not know better.\n",
      "----------------------\n",
      "To see beauty  in the midst of chaos is a gift which God instills upon the worthy and those purest of heart and faith\n",
      "----------------------\n",
      "@imraneau if they're gonna let a big company like Uber break the rules we should let the small business owners break the rules too \\_()_/\n",
      "----------------------\n",
      "To all #LVDM Antendees: Please read your confirmation emails thoroughly. It will have the passphrase for the evening. See you there!\n",
      "----------------------\n",
      "@RaunchierSide In Duden Park owner is concierge and abuser employed by BXL Environnement in charge of parks and animal mistreating ...\n",
      "----------------------\n",
      "@tomwarren not possibly because everything is stored secure in NSA provided storage  couldn't resist to make that comment. Why no editing?\n",
      "----------------------\n",
      "The @USPS Post Office is incompetent! Printing my passport pic with bad ink and notifying my weeks later. WTH!? No $15 pic REFUND?\n",
      "----------------------\n",
      "@moliviero @Uber why use dangerous service when you have the best taxi service in the world voted 5 years in a row?\n",
      "----------------------\n",
      "when you live on a hill, in the middle of nowhere, when it rains, your backroads flood and your driveway washes out \n",
      "----------------------\n",
      "My phone does this really cool thing now where once I start a phone call, the screen shuts off until I restart it or the other line hangs up\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in clf_pred_fraud_tweet_index[:20]:\n",
    "    print unselected_tweet[i]\n",
    "    print '----------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1034\n"
     ]
    }
   ],
   "source": [
    "# Apply Naive Bayes model on unselected Tweets\n",
    "gnb_pred = gnb.predict(X_unselected_tweet.toarray())\n",
    "\n",
    "gnb_pred_fraud_tweet_index = [i for i,j in enumerate(gnb_pred) if j ==1]\n",
    "print len(gnb_pred_fraud_tweet_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@BernieSanders I may have been raped at the Murfreesboro, TN VA hospital at the request of the corrupt Rutherford County Sheriff's Office.\n",
      "----------------------\n",
      "RT @CloydRivers: What pays for Free Stuff? Taxes.\n",
      "Who pays taxes? You do.\n",
      "Therefore, you pay for all Bernies Free Stuff. Merica. https\n",
      "----------------------\n",
      ".@Uber @lyft the people of Austin have spoken and you won't respect them. You'll have better luck buying off the worms in the #txlege\n",
      "----------------------\n",
      "RT @R_A_Ziemkiewicz: No pkn ze miechu Pacia od Petru labidzi e audyt zodziejstw POPSL zaszkodzi nam zagranico A donosy na rzekomy aut\n",
      "----------------------\n",
      "RT @Igy__: Nema kod nas u novinama, ima u Guardian\n",
      "Serbs rally against shady demolitions after masked crew 'tied up witnesses'\n",
      "https://t.co\n",
      "----------------------\n",
      "RT @RZIMhq: \"We refuse to believe that the bank of justice is bankrupt.\" -Dr. King \n",
      "// A reflection in #SliceOfInfinity: https://t.co/sC76g\n",
      "----------------------\n",
      "RT @michaelianblack: Donald Trump: has no policy, no character, pays no taxes, wants to have sex with his daughter, will make America great\n",
      "----------------------\n",
      "RT @Country_Voices: Dont steal, dont cheat, and dont lie, I know you got mountains to climb but always stay humble and kind. -Tim McGraw\n",
      "----------------------\n",
      "RT @HugotWords: Wanna keep your girl? Respect her, care for her, love her, text her first, make sure she knows how you feel about her and n\n",
      "----------------------\n",
      "@SundAzeD0 @notbatmanyet SamJackie is a slow thinker. \"You lie,..you are a bad liar.\" A 12 year old could think of a better come back #slow\n",
      "----------------------\n",
      "RT @screenslaver: Atty for VA Gov McAuliffe, subject of FBI probe, is general counsel for Hillary For America. Sharing best practices? http\n",
      "----------------------\n",
      "@AnnCoulter I don't know why @realDonaldTrump is putting up with this come to Jesus moment, Ronald Reagan didn't release his taxes\n",
      "----------------------\n",
      "RT @Independent: 'It's unfair to say Hillsborough police were incompetent - it takes great organisation to tell such shocking lies' https:/\n",
      "----------------------\n",
      "RT @ajplus: Divorce, abortion and same-sex marriage are illegal here. But this transgender person just won a seat in congress.\n",
      "https://t.co\n",
      "----------------------\n",
      "@mightystassen Social engineer the citypolice and if that doesn't work just straight up bribe them. It is illegal for a dog to bark all day\n",
      "----------------------\n",
      "@drewistotle The Bible is a forgery-filled fraud, the mind is what the brain does Christianity is all a lie. When you're dead your dead\n",
      "----------------------\n",
      "All done! That's the 100th small Zany Zebra packed up and on its way to @intomarlands in the #zanyzebravan 100/100! https://t.co/IZlSTtttgz\n",
      "----------------------\n",
      "Today I drove a 700hp Lancer. Let's just say I was scared for my own life and I'm a high speed specialist.\n",
      "----------------------\n",
      "RT @epiccino: Wikileaks j revelou q Temer, Serra e agora Juc so informantes da Embaixada Americana, ou seja da CIA. Quem mais? https://t\n",
      "----------------------\n",
      "@SouthernLivN FOR illegals until he saw the support trump gained for being \"anti\" illegal. Then Cruz policies began to mirror Trump\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "for i in clf_pred_fraud_tweet_index[:20]:\n",
    "    print unselected_tweet[i]\n",
    "    print '----------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Try more Category on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15000"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_pickle('../data/OAG_corpus_with_CUSP_code.pkl')\n",
    "len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10054\n"
     ]
    }
   ],
   "source": [
    "labeled_data = labeled_data[labeled_data['CUSP_NAAG']!='None']\n",
    "labeled_data = labeled_data.dropna(subset=['COMPLAINT_DESCRIPTION'], how='all')\n",
    "labeled_data = labeled_data.drop_duplicates(subset=['COMPLAINT_DESCRIPTION'])\n",
    "print len(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_data['cusp_code'] = labeled_data['cusp_code'].replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cusp_code</th>\n",
       "      <th>CUSP_NAAG</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>Residential</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>scams</th>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>misc</th>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>financial</th>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>good_n_services</th>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>government</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>utilities</th>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>travel</th>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Count\n",
       "cusp_code CUSP_NAAG             \n",
       "1         Residential        873\n",
       "2         scams             1291\n",
       "3         misc              2152\n",
       "4         financial         1552\n",
       "5         good_n_services   1379\n",
       "6         government         300\n",
       "7         utilities          922\n",
       "8         travel            1585"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Index_table = labeled_data[['cusp_code','CUSP_NAAG','NAAG_DESCRIPTION']].groupby(['cusp_code','CUSP_NAAG']).count().rename(columns={'NAAG_DESCRIPTION': 'Count'})\n",
    "Index_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "description_table = labeled_data[['CUSP_NAAG','NAAG_DESCRIPTION']].groupby(['CUSP_NAAG']).sum()\n",
    "# for i in description_table.index.values:\n",
    "#     print i,\":\"\n",
    "#     print list(set(description_table.loc[i,:][0].split(\":\")))\n",
    "#     print \"-----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_oag_doc = list(labeled_data['COMPLAINT_DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of OAG data (fraud relevent): 10054\n",
      "The length of general tweets (nonfraud relevent): 20076\n",
      "The length of whole dataset: 30130\n"
     ]
    }
   ],
   "source": [
    "# combine corpus\n",
    "raw_whole_corpus_labled = labeled_oag_doc + selected_tweet\n",
    "print \"The length of OAG data (fraud relevent):\", len(labeled_oag_doc)\n",
    "print \"The length of general tweets (nonfraud relevent):\", len(selected_tweet)\n",
    "print \"The length of whole dataset:\", len(raw_whole_corpus_labled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 8, 2, 5, 7, 1, 4, 3, 8]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "30130\n"
     ]
    }
   ],
   "source": [
    "# Creat target, label general tweets as one\n",
    "target = list(labeled_data['cusp_code'])+[0]*len(selected_tweet)\n",
    "print target[:10]\n",
    "print target[-10:]\n",
    "print len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30130x7264 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 623712 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sklearn text feature extraction -- TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=10, stop_words='english')\n",
    "X = vectorizer.fit_transform(raw_whole_corpus_labled)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train test splitd\n",
    "X_train, X_test, target_train, target_test = train_test_split(X.toarray(), target, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by Naive Bayes =', 0.7112512446067043)\n",
      "Training it took 0.3 mins\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classification\n",
    "start_time = time.time()\n",
    "gnb_9cate = GaussianNB()\n",
    "gnb_9cate.fit(X_train, target_train)\n",
    "pred = gnb_9cate.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by Naive Bayes =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by SVM with linear =', 0.8621528930191393)\n",
      "Training it took 33.5 mins\n"
     ]
    }
   ],
   "source": [
    "# SVM linear\n",
    "start_time = time.time()\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, target_train)\n",
    "pred = svc.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by SVM with linear =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy by Random Forest =', 0.8232105321385109)\n",
      "Training it took 8.5 mins\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "start_time = time.time()\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=500)\n",
    "clf = clf.fit(X_train, target_train)\n",
    "pred = clf.predict(X_test)\n",
    "end_time = time.time()\n",
    "print(\"Accuracy by Random Forest =\", 1.0*sum(target_test==pred)/len(pred))\n",
    "print \"Training it took %.1f mins\" %((end_time-start_time)/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19818x7264 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 199830 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on unselected tweet\n",
    "# Extracting features from the test data using the same vectorizer\n",
    "X_unselected_tweet = vectorizer.transform(unselected_tweet)\n",
    "X_unselected_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply SVM model on unselected Tweets\n",
    "svc_pred = svc.predict(X_unselected_tweet.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cusp_code</th>\n",
       "      <th>CUSP_NAAG</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>Residential</th>\n",
       "      <td>873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>scams</th>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>misc</th>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>financial</th>\n",
       "      <td>1552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>good_n_services</th>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>government</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>utilities</th>\n",
       "      <td>922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>travel</th>\n",
       "      <td>1585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Count\n",
       "cusp_code CUSP_NAAG             \n",
       "1         Residential        873\n",
       "2         scams             1291\n",
       "3         misc              2152\n",
       "4         financial         1552\n",
       "5         good_n_services   1379\n",
       "6         government         300\n",
       "7         utilities          922\n",
       "8         travel            1585"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Index_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Irrelevant', 'Residential', 'scams', 'misc', 'financial', 'good_n_services', 'government', 'utilities', 'travel']\n"
     ]
    }
   ],
   "source": [
    "Index_list = Index_table.index.values\n",
    "Index_list = [i[1] for i in Index_list]\n",
    "Index_list = ['Irrelevant']+Index_list\n",
    "print Index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of Irrelevant tweet: 19788\n",
      "The amount of Residential tweet: 2\n",
      "The amount of scams tweet: 4\n",
      "The amount of misc tweet: 10\n",
      "The amount of financial tweet: 3\n",
      "The amount of good_n_services tweet: 3\n",
      "The amount of government tweet: 0\n",
      "The amount of utilities tweet: 4\n"
     ]
    }
   ],
   "source": [
    "pred_fraud_tweet_index = []\n",
    "for a in range(8):\n",
    "    pred_fraud = [i for i,j in enumerate(svc_pred) if j==a]\n",
    "    print \"The amount of %s tweet: %i\" % (Index_list[a], len(pred_fraud))\n",
    "    pred_fraud_tweet_index.append(pred_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as Residential tweet:\n",
      "\n",
      "\n",
      "when you live on a hill, in the middle of nowhere, when it rains, your backroads flood and your driveway washes out \n",
      "------\n",
      "@DanConifer @abcnews Heard a lot about N/G 4 years. \"why should I pay off my property. Someone else's rent &amp; taxes can pay 4 it\"\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as scams tweet:\n",
      "\n",
      "\n",
      "@m_omart Yes, when you paid, there is an email to you, and just reply it because the one is charge of your order.\n",
      "------\n",
      "What Do You Get with CSEO? within the first 4 days of your subscription, you'll get a free on-page SEO audit of your website.\n",
      "------\n",
      "2/@homeaway: \"We can't refund your money even though it was fraud.\" Why? \"Because we sent it to @canadastays\". So I call @canadastays\n",
      "------\n",
      "@scottmstringer Spoke 2 u @ polling site election day when I'd been sent 2 wrong site. Tnx 4 calling 4 inves. I want a reciept for my ballot\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as misc tweet:\n",
      "\n",
      "\n",
      "Before draining their bank accounts dry. Or worse commit crimes and pin it on the victim. I keep getting phone calls from one scammer 2/\n",
      "------\n",
      "People are so rude, every single person in the grocery store asked what happened to me so I kept making up different outlandish stories. \n",
      "------\n",
      "@canadaposthelps is there anyway to contact the deliver driver? I am trying to get a package deliver to my office before 5pm not 8pm.\n",
      "------\n",
      ".@JohnFasoNy has sent cease and desist to @heaneyny and @JobsCouncil over mailers and tv ads claiming he was fined by state AG over lobbying\n",
      "------\n",
      "\"If my girlfriend broke up with me id be devastated... for like 3 days. 4th day id rub one out and put the pieces back together.\"\n",
      "------\n",
      "@TheRemixProject i seen your program and I want to enroll! I sent a application already but what now? How do I get involved?\n",
      "------\n",
      "Smith said he had a number of conversations with Russ Brandon. Said decision to retire the number this year was made about a month ago\n",
      "------\n",
      "RT @la_tanquista: The state is a monopoly on force, but also the repository of all socially owned value-goods and services paid for by peop\n",
      "------\n",
      "@EQBank you're 2 days too late. You owe me $5 for the overdraft fee I was charged because I couldn't move my money\n",
      "------\n",
      "RT @IC_ActivityLog: DARLA REQUESTED I PROVIDE HER WITH THE PHONE NUMBERS FOR THE FBI AND FCC. DARLA DID NOT HOWEVER WANT THE PHONE NUMBER F\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as financial tweet:\n",
      "\n",
      "\n",
      "I called you on your phone  you sent my shit to message this can't be what you on I'm not going to lie to creep up to your home......\n",
      "------\n",
      "@MR2sszz Well, a credit card charge necessarily has to go through the restaurant first. It's illegal, but mgmt can short waitstaff that way.\n",
      "------\n",
      "Goals would be to be able to buy whatever I want and not have an anxiety attack checking my bank account after\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as good_n_services tweet:\n",
      "\n",
      "\n",
      "@Cex I've had an email with an evoucher attached but the voucher attached was a corrupt file, could you please send it again\n",
      "------\n",
      "@AsuraVIP I can fix it myself tbh. Called my insurance company and they told me not to file because 1. She might not insurance 2. Fraud\n",
      "------\n",
      "If you pack a TOTS in-form, we advise selling him early! The more in-forms that are packed and listed, the cheaper they will get...\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as government tweet:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n",
      "Recognized as utilities tweet:\n",
      "\n",
      "\n",
      "@ATT @ATTCares #glennlurie no int'l service all weekend and u have social media mgr contact me? Where was int'l customer service #attstinks\n",
      "------\n",
      "NEVER EVER get @comcast not only does their installation service suck, when they tell you they will fix it. They lie! #comcastsucks\n",
      "------\n",
      "@OperationOppo @doodlebug0 @CWAUnion Well, in fairness to Bernie, he might have a contract with Verizon &amp; not a \"drop anytime\" plan.\n",
      "------\n",
      "@GovJVentura And I believe it is illegal for your service provider to even TELL you they were nosing into your private data!\n",
      "------\n",
      "\n",
      "\n",
      "___________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(pred_fraud_tweet_index):\n",
    "    if i != 0:\n",
    "        print \"Recognized as %s tweet:\" % (Index_list[i])\n",
    "        print \"\\n\"\n",
    "        for k in j:\n",
    "            print unselected_tweet[k]\n",
    "            print \"------\"\n",
    "    print \"\\n\"\n",
    "    print \"___________________________________________________________________________________________________________\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### customize test demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test tweet is recognized as Irrelevant tweet\n"
     ]
    }
   ],
   "source": [
    "### customize test demo\n",
    "\n",
    "test_demo = [\"I sent my money to my chase bank, it works really good! I love chase!\"]\n",
    "\n",
    "test_demo_transform = vectorizer.transform(test_demo)\n",
    "test_result = svc.predict(test_demo_transform.toarray())\n",
    "print \"The test tweet is recognized as %s tweet\" % Index_list[test_result[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test tweet is recognized as financial tweet\n"
     ]
    }
   ],
   "source": [
    "test_demo = [\"I sent my money to my chase bank, but it results that I lose my money. I wanna talk with chase bank manager tomorrow\"]\n",
    "\n",
    "test_demo_transform = vectorizer.transform(test_demo)\n",
    "test_result = svc.predict(test_demo_transform.toarray())\n",
    "print \"The test tweet is recognized as %s tweet\" % Index_list[test_result[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
